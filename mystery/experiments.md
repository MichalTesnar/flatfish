# experiment plan
- replacing what we have done before, all the methods: how to tune it online

improvements online:
- adaptive buffering, at the beggining more, basically condition it more on time (at most every 10 secs) and in the meantime keep buffering, so that you are always sure you can train
- adaptive threshold: it might be nice to lower it down once we learn a lot, what I was thinking, we could make it adaptive, what if we 
- decaying it: at the end even a bit of uncertainty we want to polish out